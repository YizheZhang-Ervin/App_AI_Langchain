import asyncio
import json
from typing import Any, Dict
from dotenv import load_dotenv
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_ollama import ChatOllama
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.prebuilt import create_react_agent
from loguru import logger

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡ï¼Œoverride=True è¡¨ç¤ºè¦†ç›–å·²å­˜åœ¨çš„å˜é‡
load_dotenv(override=True)

checkpointer = InMemorySaver()
config = {"configurable": {"thread_id": "user-001"}}


def load_servers(file_path: str = "mcp.json") -> Dict[str, Any]:
    """
    ä»æŒ‡å®šçš„ JSON æ–‡ä»¶ä¸­åŠ è½½ MCP æœåŠ¡å™¨é…ç½®ã€‚

    å‚æ•°:
        file_path (str): é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º "mcp.json"

    è¿”å›:
        Dict[str, Any]: åŒ…å« MCP æœåŠ¡å™¨é…ç½®çš„å­—å…¸ï¼Œè‹¥æ–‡ä»¶ä¸­æ²¡æœ‰ "mcpServers" é”®åˆ™è¿”å›ç©ºå­—å…¸
    """
    with open(file_path, "r", encoding="utf-8") as file:
        data = json.load(file)
        return data.get("mcpServers", {})


async def run_chat_loop() -> None:
    """
    å¯åŠ¨å¹¶è¿è¡Œä¸€ä¸ªåŸºäº MCP å·¥å…·çš„èŠå¤©ä»£ç†å¾ªç¯ã€‚

    è¯¥å‡½æ•°ä¼šï¼š
    1. åŠ è½½ MCP æœåŠ¡å™¨é…ç½®ï¼›
    2. åˆå§‹åŒ– MCP å®¢æˆ·ç«¯å¹¶è·å–å·¥å…·ï¼›
    3. åˆ›å»ºåŸºäº Ollama çš„è¯­è¨€æ¨¡å‹å’Œä»£ç†ï¼›
    4. å¯åŠ¨å‘½ä»¤è¡ŒèŠå¤©å¾ªç¯ï¼›
    5. åœ¨é€€å‡ºæ—¶æ¸…ç†èµ„æºã€‚

    è¿”å›:
        None
    """
    # 1ï¸ åŠ è½½æœåŠ¡å™¨é…ç½®
    servers_cfg = load_servers()

    # 2ï¸ åˆå§‹åŒ– MCP å®¢æˆ·ç«¯å¹¶è·å–å·¥å…·
    mcp_client = MultiServerMCPClient(servers_cfg)
    tools = await mcp_client.get_tools()
    logger.info(f"âœ… å·²åŠ è½½ {len(tools)} ä¸ª MCP å·¥å…·ï¼š {[t.name for t in tools]}")

    # 3 åˆå§‹åŒ–è¯­è¨€æ¨¡å‹
    llm = ChatOllama(model="qwen3:8b", reasoning=False)
    # 4 æ„å»ºLangGraph Agent
    # prompt = """
    # ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä½“ï¼Œå¯ä»¥è°ƒç”¨ä»¥ä¸‹å‡½æ•°ï¼š
    # 1. get_weather(city: str) â€”â€” è·å–æŒ‡å®šåœ°ç‚¹çš„å¤©æ°”
    # 2. fetch(url: str) â€”â€” è¯·æ±‚æŒ‡å®š URL å¹¶è¿”å›å†…å®¹ç½‘é¡µçš„å†…å®¹
    
    # è¯·æ ¹æ®ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¯·æ±‚ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å‡½æ•°ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§å‡½æ•°è¾“å…¥æ ¼å¼è¿”å›è°ƒç”¨æŒ‡ä»¤ã€‚
    # å¦‚æœä¸éœ€è¦è°ƒç”¨å‡½æ•°ï¼Œå°±ç›´æ¥å›ç­”ã€‚
    # """

    # ç”¨å¤©æ°”åŠ©æ‰‹MCPå·¥å…·çš„æç¤ºè¯
    # agentå°è£…ä¸ºmcpçš„æç¤ºè¯
    # é…ç½®ä½¿ç”¨mcp.json
    prompt = """
    ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä½“ï¼Œå½“ç”¨æˆ·éœ€è¦æŸ¥è¯¢å¤©æ°”æ—¶ï¼Œå¯ä»¥è°ƒç”¨chatbotå·¥å…·æ­¤æ—¶è¯·åˆ›å»ºå¦‚ä¸‹æ ¼å¼æ¶ˆæ¯è¿›è¡Œè°ƒç”¨ï¼š{"type": "human", "content": user_input}
    è¯·æ ¹æ®ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¯·æ±‚ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å‡½æ•°ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§å‡½æ•°è¾“å…¥æ ¼å¼è¿”å›è°ƒç”¨æŒ‡ä»¤ã€‚
    å¦‚æœä¸éœ€è¦è°ƒç”¨å‡½æ•°ï¼Œå°±ç›´æ¥å›ç­”ã€‚
    """

    agent = create_react_agent(model=llm, prompt=prompt, tools=tools, checkpointer=checkpointer)
    # 5. CLIèŠå¤©
    logger.info("\nğŸ¤– MCP Agent å·²å¯åŠ¨ï¼Œè¾“å…¥ 'quit' é€€å‡º")
    while True:
        user_input = input("\nä½ : ").strip()
        if user_input.lower() == "quit":
            break
        try:
            result = await agent.ainvoke({"messages": [("user", user_input)]}, config)
            print(f"\nAI: {result['messages'][-1].content}")
        except Exception as exc:
            logger.error(f"\nâš ï¸  å‡ºé”™: {exc}")

    # 6. é€€å‡ºä¼šè¯
    logger.info("ğŸ§¹ å·²é€€å‡ºä¼šè¯ï¼ŒBye!")


if __name__ == "__main__":
    # å¯åŠ¨å¼‚æ­¥äº‹ä»¶å¾ªç¯å¹¶è¿è¡ŒèŠå¤©ä»£ç†
    asyncio.run(run_chat_loop())
